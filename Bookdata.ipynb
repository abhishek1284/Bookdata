{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5553cdd6-8615-4b18-9e95-ea90a4f3ab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://books.toscrape.com/catalogue/page-1.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-2.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-3.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-4.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-5.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-6.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-7.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-8.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-9.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-10.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-11.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-12.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-13.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-14.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-15.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-16.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-17.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-18.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-19.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-20.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-21.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-22.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-23.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-24.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-25.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-26.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-27.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-28.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-29.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-30.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-31.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-32.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-33.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-34.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-35.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-36.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-37.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-38.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-39.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-40.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-41.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-42.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-43.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-44.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-45.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-46.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-47.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-48.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-49.html...\n",
      "Scraping https://books.toscrape.com/catalogue/page-50.html...\n",
      "Data has been successfully saved to 'books_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Define the base URL\n",
    "base_url = \"https://books.toscrape.com/catalogue/\"\n",
    "\n",
    "# Function to get soup object from a URL\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return BeautifulSoup(response.text, 'html.parser')\n",
    "    else:\n",
    "        print(f\"Failed to fetch page: {url}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract book details (name, price, link) from a single page\n",
    "def extract_books_from_page(url):\n",
    "    soup = get_soup(url)\n",
    "    if not soup:\n",
    "        return []\n",
    "    \n",
    "    books = []\n",
    "    for book in soup.find_all(\"article\", class_=\"product_pod\"):\n",
    "        title = book.h3.a[\"title\"]\n",
    "        price = book.find(\"p\", class_=\"price_color\").text\n",
    "        book_link = book.h3.a[\"href\"]\n",
    "        # Normalize the link by combining it with the base URL\n",
    "        full_link = base_url + book_link.replace(\"../\", \"\")\n",
    "        books.append({\"name\": title, \"price\": price, \"link\": full_link})\n",
    "    return books\n",
    "\n",
    "# Function to scrape all pages\n",
    "def scrape_all_books():\n",
    "    all_books = []\n",
    "    page_url = \"page-1.html\"\n",
    "    while page_url:\n",
    "        full_url = base_url + page_url\n",
    "        print(f\"Scraping {full_url}...\")\n",
    "        soup = get_soup(full_url)\n",
    "        if not soup:\n",
    "            break\n",
    "        \n",
    "        # Extract book details from the current page\n",
    "        all_books.extend(extract_books_from_page(full_url))\n",
    "        \n",
    "        # Find the \"next\" button\n",
    "        next_page = soup.find(\"li\", class_=\"next\")\n",
    "        page_url = next_page.a[\"href\"] if next_page else None\n",
    "    return all_books\n",
    "\n",
    "# Save data to CSV\n",
    "def save_to_csv(data, filename):\n",
    "    keys = [\"name\", \"price\", \"link\"]\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    books = scrape_all_books()\n",
    "    save_to_csv(books, \"books_data.csv\")\n",
    "    print(\"Data has been successfully saved to 'books_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8ce4f-27ac-433b-8fbb-553adb5a27ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
